{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38538308-567a-47e7-8cd9-93e03c2e4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAiHLi5BQN2Truo7mrSpDRRo6G2TnnUGsA\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b0482-c574-4a86-9c1a-47937b3bd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_gemini(input_sentence):\n",
    "    response = model.generate_content(\n",
    "        input_sentence,\n",
    "        safety_settings={\n",
    "            'HARM_CATEGORY_SEXUALLY_EXPLICIT':'block_none',\n",
    "            'HARM_CATEGORY_HATE_SPEECH':'block_none',\n",
    "            'HARM_CATEGORY_HARASSMENT':'block_none',\n",
    "            'HARM_CATEGORY_DANGEROUS_CONTENT':'block_none'\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "    # print(response.text)\n",
    "        return response.text\n",
    "    except:\n",
    "        print(response.prompt_feedback)\n",
    "        # return None\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bdabc8-f309-42af-a495-dd436d3930bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_content_gemini(\"Crawl data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b751c7-9fb9-4c4e-8b10-1d4a5fa3ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_insights = \"\"\"\n",
    "Q: How to build MLOPs for predict realestate price in production?\n",
    "A: First. You have to crawl data. You extract, transform and insert to database. Moreover, you have to build training dataset to build AI model. To more efficiently, you can ensemble model to make predict result more stable\"\n",
    "-----------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab61d6-5b21-41d3-bc73-db52c0146856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crawl_data(source = 'meeyland'):\n",
    "    return f\"Start to crawl data from {source}\"\n",
    "\n",
    "def _clean_data(source = 'meeyland'):\n",
    "    return f\"Start to clean data from {source}\"\n",
    "\n",
    "def _insert_data(source = 'meeyland'):\n",
    "    return f\"Start to insert clean data to database\"\n",
    "\n",
    "def _build_offline_batch_data():\n",
    "    return f\"Build Offline batch data to train model\"\n",
    "\n",
    "def _train_price_prediction_model(model_name):\n",
    "    return f\"Start to train {model_name}\"\n",
    "\n",
    "def _get_information_about_train_experiment(experiment_id):\n",
    "    return f\"Get all metrics from {experiment_id}\"\n",
    "\n",
    "def _train_ensemble_model():\n",
    "    return f\"Start to train ensemble model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa38c0-8f93-4de1-aa5c-748bed8d0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_description = \"\"\"\n",
    "Function: _crawl_data\n",
    "    Description:\n",
    "        Crawl realestate data from source\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "\n",
    "Function: _clean_data\n",
    "    Description:\n",
    "        - Clean raw realestate data\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _insert_data\n",
    "    Description:\n",
    "        - Insert clean data to database\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _build_offline_batch_data\n",
    "    Decription:\n",
    "        - Build batch data for training AI model\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _train_price_prediction_model\n",
    "    Description:\n",
    "        - Training Price Prediction Model. Support models: lightgbm, catboost, xgboost\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['cat', 'lgbm', 'xgb']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _get_information_about_train_experiment\n",
    "    Description:\n",
    "        Get machine learning metrics about train experiment:\n",
    "            - explained_variance\n",
    "            - neg_mean_absolute_percentage_error\n",
    "            - neg_root_mean_squared_error\n",
    "            - max_error\n",
    "    Params:\n",
    "        experiment_id\n",
    "        - string\n",
    "        - Default: \"hcm_knr_realestate_DATN_V4\"\n",
    "        - Sample: \"hcm_knr_realestate_DATN_V4\"\n",
    "    Output:\n",
    "        - Information about each training metrics\n",
    "\n",
    "Function: _train_ensemble_model\n",
    "    Description:\n",
    "        - Train ensemble model from single pretrained models: lgbm, xgb, ...\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f2245-7116-4ec8-8453-a8ae9cb216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_PROMPT_TEMPLATE = \"\"\"You are a controller, you receive below query from user, utilize the insights and choose what is the action from given functions\n",
    "\n",
    "Query: $$QUERY$$\n",
    "\n",
    "Insights: $$INSIGHTS$$\n",
    "\n",
    "List function:\n",
    "$$FUNCTIONS_DECRIPTION$$\n",
    "\n",
    "The response should be exactly like format and don't say anything else:\n",
    "```json\n",
    "{\n",
    "    \"observation\": <what is the current situation, what should follow>,\n",
    "    \"guidelines\": <what is the most suitable action in this situation and why>,\n",
    "    \"actions\": [{\n",
    "        \"fn\": <function name 1>,\n",
    "        \"params\": <function param 1>\n",
    "    }, {\n",
    "        \"fn\": <function name 2>,\n",
    "        \"params\": <function param 2>\n",
    "    }]\n",
    "}\n",
    "```\n",
    "RESPONSE:\n",
    "```json\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27a9c8-cdce-42d2-a573-a91ec2b9aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_insights = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_candidate(obj):\n",
    "    actions = obj['actions']\n",
    "    try:\n",
    "        if len(actions):\n",
    "            return actions[0]\n",
    "    except:\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca83c62-a88c-4476-81bc-3b4932b64aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I want to crawl data from realestate source\"\n",
    "test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# eval(generate_content_gemini(test_inputs))\n",
    "result = generate_content_gemini(test_inputs)\n",
    "\n",
    "\n",
    "result = json.loads(result.replace(\"`\", \"\").replace(\"\\n\", \"\"))\n",
    "func_obj = get_best_candidate(result)\n",
    "print(func_obj)\n",
    "\n",
    "if func_obj['fn'] == '_crawl_data':\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e957a-cc49-43d4-b384-f5b2bd77b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Train ensemble model\"\n",
    "# test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# # eval(generate_content_gemini(test_inputs))\n",
    "# print(generate_content_gemini(test_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8646092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_obj_by_response(response):\n",
    "    result = json.loads(response.replace(\"`\", \"\").replace(\"\\n\", \"\"))\n",
    "    func_obj = get_best_candidate(result)\n",
    "    return func_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e079f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 426.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from get_raw_data import crawl_meeyland_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd0966-bb80-40a4-82a4-4cf8bcebf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    query = message\n",
    "    promp_with_input = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "    response = generate_content_gemini(promp_with_input)\n",
    "    func_obj = get_func_obj_by_response(response)\n",
    "\n",
    "    if func_obj['fn'] == '_crawl_data':\n",
    "        crawl_meeyland()\n",
    "    yield str(func_obj)\n",
    "gr.ChatInterface(slow_echo).launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
