{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38538308-567a-47e7-8cd9-93e03c2e4a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAiHLi5BQN2Truo7mrSpDRRo6G2TnnUGsA\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51b0482-c574-4a86-9c1a-47937b3bd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_gemini(input_sentence):\n",
    "    response = model.generate_content(\n",
    "        input_sentence,\n",
    "        safety_settings={\n",
    "            'HARM_CATEGORY_SEXUALLY_EXPLICIT':'block_none',\n",
    "            'HARM_CATEGORY_HATE_SPEECH':'block_none',\n",
    "            'HARM_CATEGORY_HARASSMENT':'block_none',\n",
    "            'HARM_CATEGORY_DANGEROUS_CONTENT':'block_none'\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "    # print(response.text)\n",
    "        return response.text\n",
    "    except:\n",
    "        print(response.prompt_feedback)\n",
    "        # return None\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bdabc8-f309-42af-a495-dd436d3930bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Step 1: Choose a Web Crawling Framework**\\n\\n* **Beautiful Soup (Python):** Easy-to-use, focuses on extracting data from HTML and XML documents.\\n* **Scrapy (Python):** Open-source framework for large-scale web crawling and data extraction.\\n* **Selenium (Python):** Controls web browsers to simulate human behavior and interact with dynamic elements.\\n\\n**Step 2: Define Crawl Parameters**\\n\\n* **Start URLs:** The initial pages to crawl.\\n* **Follow links:** Determine which links to follow based on patterns or depth.\\n* **Crawl depth:** The number of levels to crawl from the start URLs.\\n* **Page limits:** Set a limit on the number of pages to crawl.\\n\\n**Step 3: Write Extraction Logic**\\n\\nUse the chosen framework to parse web pages and extract the desired data. This involves identifying relevant elements, such as:\\n\\n* **XPath:** Selects nodes in an XML document based on a path expression.\\n* **CSS Selectors:** Selects elements based on CSS styles.\\n* **Regular Expressions:** Finds matches based on patterns.\\n\\n**Step 4: Store Extracted Data**\\n\\nSave the extracted data in a suitable format:\\n\\n* **Databases:** Store data in relational or NoSQL databases.\\n* **Spreadsheets:** Create spreadsheets in formats like CSV or Excel.\\n* **JSON or XML:** Use structured data formats for easy parsing.\\n\\n**Step 5: Handle Dynamic Content**\\n\\nFor websites with dynamic content (e.g., JavaScript-generated elements), consider:\\n\\n* **JavaScript Rendering:** Use headless browsers to execute JavaScript and extract data.\\n* **AJAX Handling:** Intercept and parse AJAX requests.\\n* **DOM Manipulation:** Modify the DOM tree to extract hidden data.\\n\\n**Step 6: Respect Robot Exclusion Standard**\\n\\nFollow the Robot Exclusion Standard (robots.txt) to avoid crawling websites that request avoidance.\\n\\n**Tips:**\\n\\n* **Use caching:** Store previously crawled pages to avoid re-crawling.\\n* **Handle errors gracefully:** Expect errors and handle them to ensure continued crawling.\\n* **Monitor crawling:** Track progress, identify issues, and adjust parameters accordingly.\\n* **Be ethical:** Avoid excessive crawling or harmful practices.\\n* **Consider legal implications:** Make sure crawling complies with website terms of service and privacy laws.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_content_gemini(\"Crawl data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b751c7-9fb9-4c4e-8b10-1d4a5fa3ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_insights = \"\"\"\n",
    "Q: How to build MLOPs for predict realestate price in production?\n",
    "A: First. You have to crawl data. You extract, transform and insert to database. Moreover, you have to build training dataset to build AI model. To more efficiently, you can ensemble model to make predict result more stable\"\n",
    "-----------\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ab61d6-5b21-41d3-bc73-db52c0146856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crawl_data(source = 'meeyland'):\n",
    "    return f\"Start to crawl data from {source}\"\n",
    "\n",
    "def _clean_data(source = 'meeyland'):\n",
    "    return f\"Start to clean data from {source}\"\n",
    "\n",
    "def _insert_data(source = 'meeyland'):\n",
    "    return f\"Start to insert clean data to database\"\n",
    "\n",
    "def _build_offline_batch_data():\n",
    "    return f\"Build Offline batch data to train model\"\n",
    "\n",
    "def _train_price_prediction_model(model_name):\n",
    "    return f\"Start to train {model_name}\"\n",
    "\n",
    "def _get_information_about_train_experiment(experiment_id):\n",
    "    return f\"Get all metrics from {experiment_id}\"\n",
    "\n",
    "def _train_ensemble_model():\n",
    "    return f\"Start to train ensemble model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afa38c0-8f93-4de1-aa5c-748bed8d0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_description = \"\"\"\n",
    "Function: _crawl_data\n",
    "    Description:\n",
    "        Crawl realestate data from source\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "\n",
    "Function: _clean_data\n",
    "    Description:\n",
    "        - Clean raw realestate data\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _insert_data\n",
    "    Description:\n",
    "        - Insert clean data to database\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _build_offline_batch_data\n",
    "    Decription:\n",
    "        - Build batch data for training AI model\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _train_price_prediction_model\n",
    "    Description:\n",
    "        - Training Price Prediction Model. Support models: lightgbm, catboost, xgboost\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['cat', 'lgbm', 'xgb']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _get_information_about_train_experiment\n",
    "    Description:\n",
    "        Get machine learning metrics about train experiment:\n",
    "            - explained_variance\n",
    "            - neg_mean_absolute_percentage_error\n",
    "            - neg_root_mean_squared_error\n",
    "            - max_error\n",
    "    Params:\n",
    "        experiment_id\n",
    "        - string\n",
    "        - Default: \"hcm_knr_realestate_DATN_V4\"\n",
    "        - Sample: \"hcm_knr_realestate_DATN_V4\"\n",
    "    Output:\n",
    "        - Information about each training metrics\n",
    "\n",
    "Function: _train_ensemble_model\n",
    "    Description:\n",
    "        - Train ensemble model from single pretrained models: lgbm, xgb, ...\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78f2245-7116-4ec8-8453-a8ae9cb216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_PROMPT_TEMPLATE = \"\"\"You are a controller, you receive below query from user, utilize the insights and choose what is the action from given functions\n",
    "\n",
    "Query: $$QUERY$$\n",
    "\n",
    "Insights: $$INSIGHTS$$\n",
    "\n",
    "List function:\n",
    "$$FUNCTIONS_DECRIPTION$$\n",
    "\n",
    "The response should be exactly like format and don't say anything else:\n",
    "```json\n",
    "{\n",
    "    \"observation\": <what is the current situation, what should follow>,\n",
    "    \"guidelines\": <what is the most suitable action in this situation and why>,\n",
    "    \"actions\": {\n",
    "                \"fn\": <function name>,\n",
    "                \"params\": <function param>,\n",
    "            }\n",
    "}\n",
    "```\n",
    "RESPONSE:\n",
    "```json\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee27a9c8-cdce-42d2-a573-a91ec2b9aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_insights = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca83c62-a88c-4476-81bc-3b4932b64aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"observation\": \"The user wants to crawl data from a real estate source.\",\n",
      "    \"guidelines\": \"The first step in building an MLOps pipeline for predicting real estate prices in production is to crawl data from a real estate source.\",\n",
      "    \"actions\": {\n",
      "        \"fn\": \"_crawl_data\",\n",
      "        \"params\": {\"source\": \"meeyland\"}\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to crawl data from realestate source\"\n",
    "test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# eval(generate_content_gemini(test_inputs))\n",
    "print(generate_content_gemini(test_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803e957a-cc49-43d4-b384-f5b2bd77b94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"observation\": \"Currently user want to train ensemble model. So we need to build training dataset and train single model first.\",\n",
      "    \"guidelines\": \"**Firstly, we need to build offline training dataset with function: _build_offline_batch_data.\\nSecondly, we should train single models with function: _train_price_prediction_model**. Once single models were trained, we can proceed to train ensemble.\",\n",
      "    \"actions\": {\n",
      "        \"fn\": \"_build_offline_batch_data\",\n",
      "        \"params\": {}\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"Train ensemble model\"\n",
    "test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# eval(generate_content_gemini(test_inputs))\n",
    "print(generate_content_gemini(test_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cd0966-bb80-40a4-82a4-4cf8bcebf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    query = message\n",
    "    test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "    yield generate_content_gemini(test_inputs)\n",
    "gr.ChatInterface(slow_echo).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
